07/11/2023 19:35:50.552  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: source.type, mysql
07/11/2023 19:35:50.554  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: source.database.name, test_bm1
07/11/2023 19:35:50.554  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: source.username, rds
07/11/2023 19:35:50.555  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: source.password, 123456
07/11/2023 19:35:50.555  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: source.hostname, sloth-commerce-test2.jd.163.org
07/11/2023 19:35:50.555  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: source.port, 3332
07/11/2023 19:35:50.555  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: source.table.name, *
07/11/2023 19:35:50.556  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: source.parallelism, 8
07/11/2023 19:35:50.556  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: hadoop.user.name, hdfs
07/11/2023 19:35:50.556  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: hadoop.home.dir, C:\Users\chenjianghan\Desktop\envtest
07/11/2023 19:35:50.557  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: arctic.metastore.url, thrift://ams:1260/local_catalog
07/11/2023 19:35:50.557  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: arctic.optimize.enable, true
07/11/2023 19:35:50.557  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: arctic.optimize.group.name, dbxxxx-group
07/11/2023 19:35:50.558  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: arctic.optimize.table.quota, customer:40,order_line:20,stock:50
07/11/2023 19:35:50.558  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: arctic.write.upsert.enable, true
07/11/2023 19:35:50.558  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: arctic.sink.parallelism, 4
07/11/2023 19:35:50.559  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: iceberg.test.total.size, true
07/11/2023 19:35:50.559  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: iceberg.uri, thrift://hz11-trino-arctic-0.jd.163.org:9083
07/11/2023 19:35:50.559  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: iceberg.warehouse, /user/warehouse
07/11/2023 19:35:50.559  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: iceberg.limited, false
07/11/2023 19:35:50.560  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: iceberg.limit.rate, 1024*1024
07/11/2023 19:35:50.560  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: iceberg.write.upsert.enable, true
07/11/2023 19:35:50.560  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: iceberg.sink.parallelism, 4
07/11/2023 19:35:50.561  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: hudi.catalog.path, /tmp/hive/warehouse
07/11/2023 19:35:50.561  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: hudi.hive_sync.metastore.uris, thrift://metastore:9083
07/11/2023 19:35:50.561  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: hudi.hive_sync.enable, true
07/11/2023 19:35:50.561  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: hudi.table.type, MERGE_ON_READ
07/11/2023 19:35:50.562  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: hudi.read.tasks, 4
07/11/2023 19:35:50.562  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: hudi.write.tasks, 4
07/11/2023 19:35:50.562  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: hudi.compaction.tasks, 4
07/11/2023 19:35:50.562  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: write.target-file-size-bytes, 134217728
07/11/2023 19:35:50.563  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: flink.checkpoint.timeout, 2400*1000
07/11/2023 19:35:50.563  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: flink.port, 8081
07/11/2023 19:35:50.563  INFO [com.cdc.FlinkCDC_Mysql] Loading configuration property: kafka.address, 10.196.98.23:9094
07/11/2023 19:35:52.687  WARN [org.apache.flink.runtime.util.HadoopUtils] Could not find Hadoop configuration via any of the supported methods (Flink configuration, environment variables).
07/11/2023 19:35:52.957  INFO [org.apache.hadoop.hive.conf.HiveConf] Found configuration file null
07/11/2023 19:35:53.572  WARN [org.apache.hadoop.util.NativeCodeLoader] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
07/11/2023 19:35:53.698  INFO [hive.metastore] Trying to connect to metastore with URI thrift://hz11-trino-arctic-0.jd.163.org:9083
07/11/2023 19:35:54.765  INFO [hive.metastore] Opened a connection to metastore, current connections: 1
07/11/2023 19:35:54.904  WARN [org.apache.hadoop.security.ShellBasedUnixGroupsMapping] unable to return groups for user hdfs
PartialGroupNameException Does not support partial group name resolution on Windows. GetLocalGroupsForUser error (1332): ?????????????????



	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.resolvePartialGroupNames(ShellBasedUnixGroupsMapping.java:271)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:178)
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:97)
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:51)
	at org.apache.hadoop.security.Groups$GroupCacheLoader.fetchGroupList(Groups.java:385)
	at org.apache.hadoop.security.Groups$GroupCacheLoader.load(Groups.java:320)
	at org.apache.hadoop.security.Groups$GroupCacheLoader.load(Groups.java:270)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3951)
	at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3974)
	at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4935)
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:228)
	at org.apache.hadoop.security.UserGroupInformation.getGroups(UserGroupInformation.java:1751)
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1739)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:494)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:285)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1652)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:80)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:130)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:101)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:94)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.iceberg.common.DynMethods$UnboundMethod.invokeChecked(DynMethods.java:60)
	at org.apache.iceberg.common.DynMethods$UnboundMethod.invoke(DynMethods.java:72)
	at org.apache.iceberg.common.DynMethods$StaticMethod.invoke(DynMethods.java:185)
	at org.apache.iceberg.hive.HiveClientPool.newClient(HiveClientPool.java:63)
	at org.apache.iceberg.hive.HiveClientPool.newClient(HiveClientPool.java:34)
	at org.apache.iceberg.ClientPoolImpl.get(ClientPoolImpl.java:125)
	at org.apache.iceberg.ClientPoolImpl.run(ClientPoolImpl.java:56)
	at org.apache.iceberg.ClientPoolImpl.run(ClientPoolImpl.java:51)
	at org.apache.iceberg.hive.CachedClientPool.run(CachedClientPool.java:122)
	at org.apache.iceberg.hive.HiveCatalog.createNamespace(HiveCatalog.java:281)
	at org.apache.iceberg.flink.FlinkCatalog.createDatabase(FlinkCatalog.java:203)
	at org.apache.iceberg.flink.FlinkCatalog.open(FlinkCatalog.java:120)
	at org.apache.flink.table.catalog.CatalogManager.registerCatalog(CatalogManager.java:195)
	at org.apache.flink.table.api.internal.TableEnvironmentImpl.createCatalog(TableEnvironmentImpl.java:1297)
	at org.apache.flink.table.api.internal.TableEnvironmentImpl.executeInternal(TableEnvironmentImpl.java:1122)
	at org.apache.flink.table.api.internal.TableEnvironmentImpl.executeSql(TableEnvironmentImpl.java:742)
	at com.cdc.FlinkCDC_Mysql.sinkIcebergFull(FlinkCDC_Mysql.java:132)
	at com.cdc.FlinkCDC_Mysql.main(FlinkCDC_Mysql.java:75)
07/11/2023 19:35:54.936  INFO [hive.metastore] Connected to metastore.
07/11/2023 19:37:17.900  INFO [org.apache.iceberg.BaseMetastoreCatalog] Table properties set at catalog level through catalog properties: {}
07/11/2023 19:37:18.024  INFO [org.apache.iceberg.BaseMetastoreTableOperations] Refreshing table metadata from new version: hdfs://hz11-trino-arctic-0.jd.163.org:8020/user/warehouse/db4485.db/customer_iceberg/metadata/00000-d17d27b7-7a90-47d2-bb16-1046b07a9300.metadata.json
